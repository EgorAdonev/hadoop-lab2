Index: src/main/java/bdtc/lab2/AvgPerGroupUserCounter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/bdtc/lab2/AvgPerGroupUserCounter.java b/src/main/java/bdtc/lab2/AvgPerGroupUserCounter.java
--- a/src/main/java/bdtc/lab2/AvgPerGroupUserCounter.java	
+++ b/src/main/java/bdtc/lab2/AvgPerGroupUserCounter.java	(date 1652820949336)
@@ -2,13 +2,11 @@
 
 import lombok.AllArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
-import org.apache.spark.api.java.JavaPairRDD;
 import org.apache.spark.api.java.JavaRDD;
 import org.apache.spark.sql.Dataset;
 import org.apache.spark.sql.Encoders;
 import org.apache.spark.sql.Row;
 import org.apache.spark.sql.functions;
-import scala.Tuple2;
 
 import java.time.LocalDateTime;
 import java.time.format.DateTimeFormatter;
@@ -32,56 +30,72 @@
             .parseDefaulting(YEAR, 2018)
             .toFormatter();
 
+    static HashMap<String, String> groupAndUserMap;
+    {
+        Stream.of(new String[][]{
+                {"group1", "user1"},
+                {"group2", "user2"},
+                {"group3", "user3"},
+                {"group4", "user4"},
+                {"group5", "user5"},
+                {"group6", "user6"},
+                {"group7", "user7"},
+                {"group8", "user8"}
+        }).collect(Collectors.toMap(data -> data[0], data -> data[1]));
+    }
+
     /**
      * Функция подсчета количества логов разного уровня в час.
      * Парсит строку лога, в т.ч. уровень логирования и час, в который событие было зафиксировано.
-     * @param groupMap - вход  для анализа
+     * @param inputDataset - входной DataSet для анализа
      * @return результат подсчета в формате JavaRDD
      */
-    public static JavaRDD<Tuple2<String,Integer>> countAvgPerGroupUser(JavaRDD<String> messages,JavaRDD<String> groupMap) {
+    public static JavaRDD<Row> countAvgPerGroupUser(Dataset<String> inputDataset) {
         //split by row using newline symbol)
-        JavaRDD<String> groupRows = groupMap.map(rows -> Arrays.toString(rows.split("\n")));
-        JavaPairRDD<String,String> groupAndUserPair = groupRows.mapToPair(map -> {
-           String[] userAndGroup = map.split(",");
-           return new Tuple2<String,String>(userAndGroup[0],userAndGroup[1]);
-        });
-        List<Tuple2<String,String>> listUserAndGroup =  groupAndUserPair.collect();
+        Dataset<String> words = inputDataset.map(s -> Arrays.toString(s.split("\n")), Encoders.STRING());
+        int group1Count,group2Count,group3Count,group4Count,group5Count,group6Count,group7Count,group8Count;
+        //split by comma
+        Dataset<UserRecord> userDataset = words.map(s -> {
+            String[] fields = s.split(",");
+            LocalDateTime date = LocalDateTime.parse(fields[2], formatter);
+            groupAndUserMap.forEach((k, v) -> v.equals(fields[0]));
+            if( groupAndUserMap.get("group1").equals(fields[0]) ){
+                for (Map.Entry<String, String> entry : groupAndUserMap.entrySet()) {
+                    if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group1")){
 
-        JavaRDD<String> words = messages.map(s -> Arrays.toString(s.split("\n")));
-        JavaPairRDD<String,Integer> msg  = words.mapToPair(map -> {
-            String[] field = map.split(",");
-            String group1 = "";
-            String group2 = "";
-            for (Tuple2 entry: listUserAndGroup) {
-                if(entry._1().equals(field[0])) {
-                    group1 = (String) entry._2();
-                }
-            }
-            return new Tuple2<String,Integer>(group1+"|"+field[0],1);
-        });
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group2")){
+
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group3")){
+
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group4")){
+
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group5")){
+
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group6")){
+
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group7")){
 
-        JavaPairRDD<String,Integer> msg2  = words.mapToPair(map -> {
-            String[] field = map.split(",");
-            String group2 = "";
-            for (Tuple2 entry: listUserAndGroup) {
-                if(entry._1().equals(field[1])) {
-                    group2 = (String) entry._2();
-                }
+                    } else if(entry.getValue().equals(fields[0])&&entry.getKey().equals("group8")){
+
+                    }
+                }//groupAndUserMap.containsKey()
             }
-            return new Tuple2<String,Integer>(group2+"|"+field[1],1);
-        });
-        JavaPairRDD<String,Integer> grouped = msg.union(msg2);
+            groupAndUserMap.get("");
+            return new UserRecord(fields[0], fields[1], date, fields[3]);
+            }, Encoders.bean(UserRecord.class))
+                .coalesce(1);
 
         // Группирует по значениям часа и уровня логирования Group by sender
-        JavaPairRDD<String, Integer> t = grouped.reduceByKey((a,b) -> {
-           return a + b;
-        });
-        JavaRDD<Tuple2<String,Integer>> resultRDD = t.map(j -> {
-            return new Tuple2<String,Integer>(j._1(),j._2());
-        });
+        Dataset<Row> t = userDataset.groupBy("senderUser")
+                .count()
+                .toDF("senderUser", "receiverUser", "datetime", "msg")
+                // сортируем по времени лога - для красоты
+                .sort(functions.avg("senderUser"));
+        List list = t.collectAsList();
+
         log.info("===========RESULT=========== ");
-
-        return resultRDD;
+        t.show();
+        return t.toJavaRDD();
     }
 
 }
